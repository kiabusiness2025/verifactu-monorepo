# AI Gateway - Configuraci√≥n y Uso

## ¬øQu√© es AI Gateway?

AI Gateway de Vercel te permite:

- ‚úÖ Cambiar entre **100+ modelos** sin c√≥digo adicional
- ‚úÖ Un √∫nico punto de autenticaci√≥n (una sola clave API)
- ‚úÖ Logging y monitoreo centralizado
- ‚úÖ Rate limiting y failover autom√°tico
- ‚úÖ Soporte para OpenAI, Anthropic, xAI, Google y m√°s

## Estado Actual en Verifactu

| Componente        | Estado         | Detalles                              |
| ----------------- | -------------- | ------------------------------------- |
| Clave API         | ‚úÖ Configurada | `CLAVE_API_AI_VERCEL` en `.env.local` |
| Endpoint de chat  | ‚úÖ Configurado | `/api/chat` usa AI Gateway            |
| Logs en Vercel    | üìä Disponibles | Dashboard de AI Gateway en Vercel     |
| Modelos m√∫ltiples | üìñ Documentado | `lib/ai-gateway.ts` con configuraci√≥n |

## Clave API

Tu clave de AI Gateway:

```
vck_5EGDA4EFpVotU1VYVM9OZ2P3zFYpr01oJG2fKCKd0dWYN2kwqn1HR4qa
```

Guardada en: `.env.local` como `CLAVE_API_AI_VERCEL`

## Modelos Disponibles

### OpenAI (Recomendado para Isaak)

```typescript
'openai/gpt-4-turbo'; // Mejor para an√°lisis contable
'openai/gpt-4'; // M√°s potente, m√°s caro
'openai/gpt-3.5-turbo'; // M√°s r√°pido, m√°s barato
```

### Anthropic (Claude)

```typescript
'anthropic/claude-3-opus'; // Mejor reasoning
'anthropic/claude-3-sonnet'; // Balance velocidad-calidad
'anthropic/claude-3-haiku'; // M√°s r√°pido
```

### xAI (Grok)

```typescript
'xai/grok-2'; // Reasoning y an√°lisis general
```

### Google (Gemini)

```typescript
'google/gemini-pro'; // R√°pido y econ√≥mico
```

## Configuraci√≥n Actual del Chat

El endpoint `/api/chat` est√° configurado para:

1. Usar AI Gateway como base URL: `https://ai-gateway.vercel.sh/v1`
2. Autenticar con `CLAVE_API_AI_VERCEL`
3. Usar `gpt-4-turbo` por defecto
4. Fallback a OpenAI directo si no hay clave

```typescript
// apps/app/app/api/chat/route.ts
const aiGatewayClient = createOpenAI({
  apiKey: process.env.CLAVE_API_AI_VERCEL,
  baseURL: 'https://ai-gateway.vercel.sh/v1',
});

const result = await streamText({
  model: aiGatewayClient('openai/gpt-4-turbo'),
  system: buildIsaakSystem(contextType),
  messages,
});
```

## Cambiar de Modelo

Para usar un modelo diferente en el chat:

```typescript
// En /api/chat/route.ts
// Opci√≥n 1: Cambiar globalmente
model: aiGatewayClient('anthropic/claude-3-sonnet'),

// Opci√≥n 2: Basado en contexto
const modelMap = {
  'dashboard': 'openai/gpt-4-turbo',
  'landing': 'openai/gpt-3.5-turbo',
  'admin': 'anthropic/claude-3-opus',
};
model: aiGatewayClient(modelMap[contextType]),
```

## Ver Logs en Vercel

1. Ir a: https://vercel.com/dashboard
2. Proyecto: `verifactu-monorepo`
3. Men√∫ izquierdo: **AI Gateway**
4. Ver:
   - Solicitudes procesadas
   - Costos por modelo
   - Latencia y errores
   - Uso por aplicaci√≥n

## Ejemplo de Uso Completo

```typescript
import { createOpenAI } from '@ai-sdk/openai';
import { streamText } from 'ai';

export async function POST(req: Request) {
  const apiKey = process.env.CLAVE_API_AI_VERCEL;

  if (!apiKey) {
    throw new Error('AI Gateway key not found');
  }

  const aiClient = createOpenAI({
    apiKey,
    baseURL: 'https://ai-gateway.vercel.sh/v1',
  });

  const { messages } = await req.json();

  const result = await streamText({
    model: aiClient('openai/gpt-4-turbo'),
    system: 'Eres Isaak, asistente experto en contabilidad...',
    messages,
    temperature: 0.7,
  });

  return result.toDataStreamResponse();
}
```

## Comparar Modelos

| Modelo          | Coste | Velocidad  | Contexto | Mejor para               |
| --------------- | ----- | ---------- | -------- | ------------------------ |
| GPT-4 Turbo     | $     | Normal     | 128k     | **An√°lisis contable** ‚úÖ |
| GPT-4           | $$    | Lento      | 8k       | Tareas muy complejas     |
| GPT-3.5 Turbo   | $     | R√°pido     | 4k       | Respuestas r√°pidas       |
| Claude 3 Opus   | $$    | Normal     | 200k     | Reasoning profundo       |
| Claude 3 Sonnet | $     | R√°pido     | 200k     | Balance general          |
| Claude 3 Haiku  | $     | Muy r√°pido | 200k     | Respuestas inmediatas    |
| Grok 2          | $     | Normal     | 128k     | Reasoning y an√°lisis     |
| Gemini Pro      | $     | R√°pido     | 32k      | Econ√≥mico y r√°pido       |

## Pr√≥ximos Pasos

- [ ] **Monitorear costos** en Vercel AI Gateway
- [ ] **A/B Testing**: Comparar GPT-4 vs Claude para an√°lisis contable
- [ ] **Optimizar prompts**: Diferentes sistemas para cada modelo
- [ ] **Rate limiting**: Configurar l√≠mites en Vercel si es necesario
- [ ] **Cach√©**: Implementar cach√© de respuestas comunes

## Referencias

- [Documentaci√≥n Oficial](https://vercel.com/docs/ai-gateway)
- [Modelos Soportados](https://vercel.com/docs/ai-gateway#models)
- [Precios](https://vercel.com/docs/ai-gateway#pricing)
- [Dashboard](https://vercel.com/dashboard)
